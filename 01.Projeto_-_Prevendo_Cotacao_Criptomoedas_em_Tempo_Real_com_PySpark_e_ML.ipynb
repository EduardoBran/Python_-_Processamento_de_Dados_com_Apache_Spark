{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a101b1",
   "metadata": {},
   "source": [
    "# <span style=\"color: green; font-size: 40px; font-weight: bold;\"> Projeto (Regressão) </span>\n",
    "\n",
    "<br> <br>\n",
    "\n",
    "# Prevendo a Cotação de Criptomoedas em Tempo Real com PySpark e Machine Learning\n",
    "\n",
    "<br>\n",
    "\n",
    "### Contexto\n",
    "\n",
    "Neste mini-projeto, vamos explorar um importante contexto de negócio na área de finanças: a **previsão da cotação de criptomoedas**. O projeto será desenvolvido desde a concepção do problema de negócio até a entrega de um modelo preditivo, utilizando ferramentas comuns de análise de dados no dia a dia de um Cientista de Dados. Apesar do foco ser em ferramentas de análise de dados, o projeto não serve como aconselhamento financeiro.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "O objetivo deste mini-projeto é **construir um modelo de Machine Learning capaz de prever a cotação de criptomoedas**. Usaremos dados históricos do Bitcoin para treinar o modelo. O Bitcoin, lançado em 2009 pelo anônimo Satoshi Nakamoto, é a criptomoeda mais antiga e conhecida. Servindo como meio descentralizado de troca digital, as transações de Bitcoin são verificadas e registradas em um livro público distribuído chamado Blockchain. O modelo deve ser capaz de prever a cotação do Bitcoin em tempo real a partir de novos dados de entrada. Este projeto pode ser estendido para outras criptomoedas ou instrumentos financeiros com dados de cotação disponíveis.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Pergunta de Negócio Principal\n",
    "\n",
    "> \"Como podemos prever a cotação futura do Bitcoin usando dados históricos?\"\n",
    "\n",
    "<br>\n",
    "\n",
    "### Entregável\n",
    "\n",
    "O entregável deste mini-projeto será um **modelo de Machine Learning treinado para prever a cotação do Bitcoin**. O modelo será desenvolvido utilizando dados históricos de cotação do Bitcoin e será capaz de fazer previsões em tempo real com base em novos dados de entrada. O processo incluirá a concepção do problema de negócio, preparação dos dados, desenvolvimento do modelo, e a entrega do modelo preditivo.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Sobre o Conjunto de Dados\n",
    "\n",
    "Os dados utilizados neste mini-projeto abrangem o período de 2011 a 2021. O arquivo CSV contém registros OHLC (Open, High, Low, Close) da cotação do Bitcoin, Volume em BTC e Volume na moeda (dólar).\n",
    "\n",
    "A última coluna indica o preço ponderado do Bitcoin. Os carimbos de data/hora (timestamp) estão em hora Unix. Timestamps sem atividade têm seus campos de dados preenchidos com NaNs. Se estiver faltando um carimbo de data/hora ou houver saltos, isso pode ser devido à inatividade da Exchange, inexistência da Exchange, ou outros erros técnicos na coleta dos dados.\n",
    "\n",
    "Optamos por não usar dados do ano de 2022 devido à sua natureza atípica, mas você pode incluir esses dados e treinar novamente o modelo se desejar.\n",
    "\n",
    "<br>\n",
    "\n",
    "Para este projeto, utilizaremos o conjunto de dados \"Bitcoin Historical Data\", que contém quase 5 milhões de linhas e informações detalhadas sobre as transações de Bitcoin ao longo do tempo. O conjunto de dados inclui dados sobre preços de abertura, fechamento, máximo e mínimo, volume de Bitcoins negociados, volume em moeda fiduciária e preço ponderado. Além disso, uma coluna adicional dateTime foi criada para converter os timestamps Unix em um formato de data e hora legível.\n",
    "\n",
    "<br>\n",
    "\n",
    "<table border=\"2\">\n",
    "  <tr>\n",
    "    <th style=\"text-align: center; font-size: 16px;\">Nome da Coluna</th>\n",
    "    <th style=\"text-align: center; font-size: 16px;\">Tipo de Dado</th>\n",
    "    <th style=\"text-align: center; font-size: 16px;\">Descrição</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Timestamp</td>\n",
    "    <td>integer</td>\n",
    "    <td>Representa o Unix timestamp, que é o número de segundos desde 1 de janeiro de 1970 (UTC).</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Open</td>\n",
    "    <td>double</td>\n",
    "    <td>Preço de abertura do Bitcoin no início do período de tempo.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>High</td>\n",
    "    <td>double</td>\n",
    "    <td>Preço mais alto do Bitcoin durante o período de tempo.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Low</td>\n",
    "    <td>double</td>\n",
    "    <td>Preço mais baixo do Bitcoin durante o período de tempo.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Close</td>\n",
    "    <td>double</td>\n",
    "    <td>Preço de fechamento do Bitcoin no final do período de tempo.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Volume_(BTC)</td>\n",
    "    <td>double</td>\n",
    "    <td>Volume total de Bitcoins negociados durante o período de tempo.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Volume_(Currency)</td>\n",
    "    <td>double</td>\n",
    "    <td>Volume total em moeda fiduciária (por exemplo, USD) das transações de Bitcoin durante o período.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Weighted_Price</td>\n",
    "    <td>double</td>\n",
    "    <td>Preço ponderado do Bitcoin, calculado com base nos preços e volumes das transações durante o período.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>dateTime</td>\n",
    "    <td>string</td>\n",
    "    <td>Irá representar a data e hora no formato legível, será criada a partir do Unix timestamp. <b>(Nova Coluna)</b> </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<br> <br> <br>\n",
    "\n",
    "# Importando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5196544",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "## Bibliotecas de Manipulação e Análise de Dados\n",
    "\n",
    "import pandas as pd                      # Biblioteca para manipulação e análise de dados tabulares.\n",
    "import numpy as np                       # Biblioteca para cálculos numéricos e manipulação de arrays.\n",
    "\n",
    "\n",
    "## Bibliotecas de Visualização de Dados\n",
    "\n",
    "import seaborn as sns                    # Biblioteca para visualização de dados estatísticos.\n",
    "from matplotlib import pyplot as plt     # Biblioteca para criação de gráficos e visualizações.\n",
    "\n",
    "\n",
    "## Bibliotecas Principais do PySpark\n",
    "\n",
    "import pyspark                           # Biblioteca para processamento de dados em grande escala usando clusters.\n",
    "from pyspark import SparkConf            # Configuração e criação do contexto do Spark.\n",
    "from pyspark import SparkContext         # Configuração e criação do contexto do Spark.   \n",
    "from pyspark.sql import SparkSession     # Criação e manipulação de sessões e contextos SQL no Spark.\n",
    "from pyspark.sql import SQLContext       # Criação e manipulação de sessões e contextos SQL no Spark.\n",
    "from pyspark.sql.types import *          # Tipos de dados usados na criação de schemas de DataFrames no Spark.\n",
    "from pyspark.sql.functions import *      # Funções SQL usadas para manipulação e transformação de dados no Spark.\n",
    "\n",
    "## Bibliotecas de Machine Learning no PySpark\n",
    "\n",
    "from pyspark.ml.linalg import Vectors         # Estruturas de dados para manipulação de vetores na MLlib do Spark.\n",
    "from pyspark.ml.feature import StringIndexer  # Transformação de variáveis categóricas em numéricas.\n",
    "from pyspark.ml.regression import LinearRegression      # Algoritmo de regressão linear na MLlib do Spark.\n",
    "from pyspark.mllib.evaluation import RegressionMetrics  # Métricas de avaliação para modelos de regressão.\n",
    "from pyspark.ml.stat import Correlation                 # Cálculo de correlações entre colunas de DataFrames.\n",
    "from pyspark.ml.feature import MinMaxScaler             # Normalização dos dados para um intervalo específico.\n",
    "from pyspark.ml.feature import VectorAssembler   # Combinação de múltiplas colunas em uma única coluna de vetores.\n",
    "from pyspark.ml import Pipeline          # Construção de pipelines de ML que consistem em uma sequência de etapas.\n",
    "from pyspark.ml.tuning import ParamGridBuilder    # Ferramentas para construção de grids de parâmetros.\n",
    "from pyspark.ml.tuning import CrossValidator      # Ferramentas para construção de validação cruzada.\n",
    "from pyspark.ml.tuning import CrossValidatorModel # Ferramentas para construção de validação cruzada.\n",
    "from pyspark.ml.feature import StandardScaler     # Normalização de dados para ter média zero e variância unitária.\n",
    "from pyspark.ml.evaluation import RegressionEvaluator  # Avaliação de modelos de regressão utilizando \n",
    "                                                       # métricas como RMSE e R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8edee8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Formatação das saídas\n",
    "\n",
    "# Configura o Pandas para mostrar até 200 colunas ao exibir um DataFrame\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "# Configura o Pandas para mostrar até 400 caracteres por coluna ao exibir um DataFrame\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "\n",
    "# Configuramos matplotlib_axes_logger para exibir apenas mensagens de erro \n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20637352",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Por que vamos usar o <i>PySpark</i> ao invés de utilizarmos somente <i>Linguagem Python</i>?\n",
    "\n",
    "> Antes de responder, podemos afirmar que SIM, este projeto poderia ser feito usando somente <i>Linguagem Python</i>.\n",
    "\n",
    "#### Então por que usar o PyStark?\n",
    "\n",
    "Como iremos ver a seguir, nosso conjunto de dados possui um tamanho de **317MB** e **quase 5 milhões de linhas**. Será que conseguiríamos processar esse volume de dados tão alto com Linguagem Python? Provavelmente não!\n",
    "\n",
    "<br>\n",
    "\n",
    "Portanto usaremos o **PySpark** pois o ele nos permite trabalhar em um ambiente distribuído. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a935ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n",
      "sys       : 3.9.7 (default, Sep 16 2021, 13:09:58) \n",
      "[GCC 7.5.0]\n",
      "pyspark   : 3.5.1\n",
      "findspark : 2.0.1\n",
      "numpy     : 1.22.4\n",
      "decimal   : 1.70\n",
      "matplotlib: 3.4.3\n",
      "seaborn   : 0.11.2\n",
      "pandas    : 1.3.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985b686",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Preparando o Ambiente Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf12ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/10 18:35:36 WARN Utils: Your hostname, eduardo-Inspiron-15-3520 resolves to a loopback address: 127.0.1.1; using 192.168.0.13 instead (on interface wlp0s20f3)\n",
      "24/07/10 18:35:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/10 18:35:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Definindo semente aleatória (seed) para reprodutibilidade do notebook\n",
    "rnd_seed = 23\n",
    "np.random.seed = rnd_seed\n",
    "np.random.set_state = rnd_seed\n",
    "\n",
    "# Criando o Spark Context\n",
    "sc = SparkContext(appName = \"Mini-Projeto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2888cd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.13:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Mini-Projeto3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdf128ffa90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando a sessão Spark\n",
    "spark_session = SparkSession.Builder().getOrCreate()\n",
    "\n",
    "# Visualiza o objeto spark_session\n",
    "spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0590ad2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ff33c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
